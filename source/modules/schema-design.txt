=============
Schema Design
=============

STILL WORKING ON THIS.


Learning Objectives
-------------------

Upon completing this module, students should understand:

- The importance of a good schema
- What differentiates a good schema from a bad schema
- Why this differentiation depends upon the use case


Overview
--------

- Schema design is about how data is put into documents.
- The structure of documents can affect performance.
- You will not and should not try to normalize your data.
- Your model will be built around how your data is used.


Schema Design Considerations
----------------------------

TO DO: ADD A DRAWING

- Often, there is a trade-off between:
  
  - The size of your documents
  - Number of queries you need to perform

- Your first consideration will be how to balance these.

  - You don't want to query documents full of data you're not using.
  - You don't want to run lots of queries to get all the data you need.


Find Queries and RAM
--------------------

- RAM is a precious commodity.
- Ideally, when you query a document, it will already be in memory.
- When a document is queried: 

  - The entire document is loaded into memory (if not already there).
  - This can push other documents out of memory.

- If your documents are small, more of them can fit into memory.

  - Loading them will push relatively little data out of memory.


Find Queries and Spinning Disks
-------------------------------

- If a document is not already in memory when queried, It must get from the disk into RAM.
- Even if its location is known, this involves two steps:

  - A seek (to put the read head at the beginning of the document on the disk)
  - A read (to pull the document into memory)

- For spinning disks, reading is pretty fast, but seeks are slow.
- If you need to find lots of scattered documents, this will mean lots of seeks.
- Packing data together into a single document will reduce the number of seeks.


Many Small vs. Few Large Documents
----------------------------------

- Memory management favors small documents; seek time favors large.
- How to decide?

  - Frequently accessed data should be put into one document, to minimize seeks.
  - Rarely used data should not be accessed when not being used.
  - This minimizes both the number of frequent queries, and the amount of data pushed out of memory by any query.

Scenario: Medical Patient Data
------------------------------

- When a patient comes in, record:

  - All the people and technicians they saw
  - All procedures performed
  - Patients' symptoms
  - The diagnosis
  - Medication prescribed

- Scan all the actual medical documents 

  - Keep as binary information.

- When querying or running analytics, do not use the binary data.

  - Binary data is only rarely accessed, relative to other data.

Medical Patient Data (Continued)
--------------------------------

- You could create documents that contain all data for a patient

  - people
  - procedures
  - symptoms
  - diagnosis
  - medication
  - binary data

- If you usually query only for the people, diagnosis, and procedures, this would include a lot of unused data.


Medical Patient Data (Continued)
--------------------------------

TODO: REMAKE THIS DRAWING

.. figure:: /images/data-modeling-documents-include-useless-data.png
   :align: center
   :width: 600 px
   :title: Documents with both Useful and Useless Data

.. only:: instructor

   .. note::

      - This diagram shows 8 documents in memory.
      - The green section describes data in a document which is useful.
      - The red part describes data that is not useful.
      - This wastes valuable memory space as a document is either in memory or not in memory.
      - Because of this schema design not as many documents can fit into memory as possible.
      - A better plan would be to include only people seen, diagnosis, and medications.

        - Move everything else into other collections.

Medical Patient Data (Continued)
--------------------------------

TODO: REMAKE THIS DRAWING

.. figure:: 

(Note: Continuing to digest the text below, which is drawn from a google doc, so thick of everything that follows as a placeholder.)

Now the same size of memory contains more documents - 12.  Because all of the data is useful in the documents there is more space for more documents.  This results in fewer page faults and more effective use of the most valuable resource - RAM.

Now consider another extreme.  Imagine if we were designing a system that took “samples”.  Samples can be any kind of additive update.  In our case, let us consider that each time a patient visits a different person at the doctor that is considered a sample and all the information about that patients visit to that station is put into its own document.  A visit for a person may be represented by many documents. We would get a pattern described above (efficient use of memory) but now it would take many queries or possibly a lot of I/O to gather all the documents required to resolve the query.  Consider:

DRAW:


Each rectangle describes a document in the memory map.  When having to create a large cursor MonogDB may page fault a lot since each document needs to be retrieved and may not be in RAM.  This may cause a lot of I/O and many page faults.  If using a spinning HD this could take many seeks to find the data on disk to load into RAM.  If all the data being used in this query were together then the access pattern would look like this:

DRAW:


Now the read is very fast.  It causes at most 1 page fault.  And we obey the concept of “data locality”.  Also, we take advantage of the flexible nature of documents.  The documents for each patient's visit are of different size and are “loosely structured”.  Some visits have more data in them than others and the types of data is varied.

“Belongs To” VS “Belongs In” & References:
After modeling your domain and beginning to compose documents from your objects, you will have to ask yourself if certain objects belong together or if they should be referenced.  First consider if one object “belongs to” another object.  If it does, then consider if that data “belongs in” the document.  Belongs in conditions occur when the data in question has a 1-1 relationship with the document.  No other document would claim “ownership” of that information.  Other things to consider are taking advantage of atomic operations.

If an object belongs to but does not belong in a document, then a reference will be made.  A reference is usually denormalizing the _id of one document into the other document.  Generally, this will now require 2 or more queries.

Often this is obvious but when it is not it is important to consider the consequences.  Also, is there an opportunity to “denormalize” and apply a “belongs in” relationship to the data?

Imagine you wanted to model a “card catalog” in MongoDB.  The objective is to keep track of 3 entities: books, authors and publishers.  When a user is interested in a book they will likely be interested in some details about the author such as their name as well as some publisher details.  Likewise, when viewing authors the user would like to see publishers they’ve worked with.  How could a system like this be modeled?

For a book an array of author _id’s could be embedded and thus creating a “reference” to the authors.  However, this would require multiple queries and possible extra I/O to resolve the book information.  An opportunity exists to “denormalize”  the useful author information into the book.  These would be the authors name and their _id.  It is important to always denormalize the _id as well as it will never change even if the authors name changes.  



You would not want to denormalize the other author information, such as their biography.  This is not useful in the context of the book.

Got “genre”  or “category” information, instead of a lookup table, embedding as string each category is often the best idea.  This can be indexed and books of similar category will be found in the cursor.

DRAW:


Atomic Operations:
<This may good as an exercise for the students - describe the problem and domain and see what their results are >

MongoDB has “atomic operations” on documents.  This means that when a document is updated, no other thread is updating it or reading it.  This leads to consistent reads and writes.  This is a powerful feature that provides document level transactions.  That is, any modification to any number of fields in a single document can be thought of as a transaction.  Updates to a single document either entirely happen or they do not at all.  There are no partial updates and no “dirty reads” at the document level.

Imagine an online poker game.  The 2 main domain objects are players and the poker game itself.  A game is a series of actions and states created by players.  Players may be involved in many games and sometimes more than 1 game at a time.  Every game may host multiple players and each game will have many hands that can be played.  Different types of poker games may be played as well.  How might one model this?

DRAW:


<let students do exercise in small groups (20 minutes) and then discuss their ideas>

When asking if a game “belongs to” a player we quickly see it does not - many players belong to the game.  Then we would ask ourselves, should each player exist as a full entity in the game?  And the answer is no, because players will be involved with many games and lots of player information is irrelevant to each game.  This leads us to creating a single document for every player.

For each game there are many moves players make - they are dealt cards, they make wagers, new cards come out, etc.  How to model the game?  The first idea is there is a game collection which has meta data about the game and then a document for every action a player in the game makes.  However, this creates a game which is not atomic and will possibly have lots of IO.

To model the game atomicly we should create an array of player actions and each action is an embedded document.  Certain player information is denormalized such as their name, id and other useful information to the game.

We end up with 2 collections - players and games.  A player is a single document that contains all their personal information, notes, history and meta data.  A game is represented per document and contains all the actions that pertain to that game and certain player information is denormalized so on the game document needs to be accessed during gameplay - taking advantage of atomic ops.
