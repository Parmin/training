=============
Data Modeling
=============


Learning Objectives
-------------------

Upon completing this module, students should understand:

- The importance of a good schema
- What differentiates a good schema from a bad one
- Why this depends upon the use case
- How to design a good schema


Overview
--------

- The structure of documents affects performance.
- You will not and should not try to normalize your data.
- You must build your schema around your data usage.


Schema Design Considerations
----------------------------

- You will want:
  
  - The smallest possible amount of data in each document
  - The fewest documents returned by your query/queries

- These goals are mutually exclusive.
- Schema design is about how to prioritize them.


.. only:: instructor

  .. note::

    - These are mutually exclusive because: 
    
      - The easiest way to have the smallest possible document: 
      
        - Have LOTS of documents with a tiny piece of data in each.

      - The easiest way to have few documents:
      
        - Pack all data of conceivable relevance into one BIG document.


Find Queries and RAM
--------------------

- RAM is a precious commodity.

  - Documents already in RAM load MUCH faster.

- When a document is queried that is not already in RAM:

  - A page fault occurs.
  - The document is read from disk into memory.
  - Other documents get pushed out of memory.

- Useless data will push out useful data when it gets loaded.


Find Queries and RAM (Continued)
--------------------------------

- We want to separate useful & useless data.
- If the documents are smaller (ceteris paribus):

  - You won't have to query data you're not using.
  - More useful pieces of data can fit in memory.
  - Queries on a given number of them are faster, on average.

- Try to keep documents as small as possible.


Find Queries and Spinning Disks
-------------------------------

- Suppose you query for a document not yet in RAM.
- Once its location on disk is known, the drive will do:

  - A seek (slow)
  - A read (fast)

- Querying many documents at once means many seeks.
- The same data in fewer documents means fewer seeks.

  - Even if there is some useless data in the documents, too.

.. only:: instructor

  .. note:: 

    - This applies mainly to spinning disks.
    - The performance hit is much smaller for solid state drives.


Many Small vs. Few Large Documents
----------------------------------

- Memory management favors small (and thus many) documents.
- Seek time favors few (and therefore large) documents.
- How should we prioritize these requirements?


Many Small vs. Few Large Documents (Continued)
----------------------------------------------

- Solution:

  - Data that's called together should be grouped together.
   
    - Same amount of data in 1 seek instead of many.

  - Especially if it's queried frequently.
  - Push rarely used data elsewhere.
  
- This gets us close to a good balance of: 
  
  - Reducing the number of seeks.
  - Not pulling unused data into memory (very often).


Patterns: “Belongs To” vs. “Belongs In” & References
----------------------------------------------------

- While modeling data, you will want to ask yourself: 

  - Do certain objects belong together in a document? 
  - Or should they should be referenced?

- Each of these might be useful, depending on your situation.


"Belongs To" vs. "Belongs In" & References (Continued)
------------------------------------------------------

- If an object belongs to multiple documents, reference it.
- If referencing, getting your data will now require 2 or more queries.
- Sometimes it is worthwhile to create copies of your data

  - One in each document that would otherwise reference it
  - We call this 'denormalizing'
  - Should be done with small pieces of data.


Data Modeling Scenarios: Introduction
-------------------------------------

- Now we will design some schemas.
- You'll see these ideas put into practice.
- I'll do one, then you will do one.

.. only:: instructor

  .. note::

    - Tell the students the following: 
    - We're going to go through a few scenarios.
    - As we do so, try to think ahead.
    - Ask yourself:

      - How should we model this data?
      - What are some pitfalls?

    - Think about:

      - RAM
      - Number of seeks


Scenario #1: Medical Patient Data
---------------------------------

- We are going to design a system for a hospital.
- When a patient comes in, we record:

  - All the doctors, nurses, and technicians they saw.
  - All procedures performed on them.
  - Their symptoms.
  - The diagnosis.
  - Any medication prescribed.


Medical Patient Data (Continued)
--------------------------------

- We will also record:

  - A binary scan of all the actual medical documents.

- The binary data is not used for querying/analytics.

  - It is rarely accessed.
  - Storing it is a requirement.


Medical Patient Data (Continued)
--------------------------------

- There is one common use case

  - Load previous visit data to find:

    - Doctors/nurses/technicians seen
    - Tests & results
    - Symptoms
    - Diagnosis
    - Medication


Medical Patient Data (Continued)
--------------------------------

- Possible Solution #1: create documents that contain:

  - people
  - procedures
  - symptoms
  - diagnosis
  - medication
  - binary data
  - One big document per visit, total.

.. only:: instructor

   .. note::

      - This has several advantages:

        - All data is in a single document
        
          - Just one query to call up patient info
          - Seeks will be rare

        - Simple data structure (everything is together)


Medical Patient Data (Continued)
--------------------------------

- Disadvantage of Solution #1:

  - Documents include lots of unused data.

- Let's ask: What is being used in a typical query?
- Answer:

  - people the patient saw
  - diagnoses the patient received
  - procedures performed on the patient.
  - Symptoms
  - Diagnosis


Medical Patient Data (Continued)
--------------------------------

- Solution #2: just put that stuff together!
- For all other data, put it in a another collection.
- This ensures one seek per data request most of the time.
- Rarely needed data is still available.

  - Just not in the frequently accessed documents.

Medical Patient Data (Continued)
--------------------------------

.. figure:: /images/data-model-8-in-memory.png
   :width: 700px
   :align: center


..   :title: Documents with Both Useful and Useless Data (Solution #1)

.. only:: instructor

   .. note::

      - This diagram shows 8 documents in memory.
      - The green section describes data in a document which is useful.
      - The red part describes data that is not useful.
      - This wastes valuable memory space as a document is either in memory or not in memory.
      - Because of this schema design not as many documents can fit into memory as possible.
      - A better plan would be to include only people seen, diagnosis, and medications.

        - Move everything else into other collections.


Medical Patient Data (Continued)
--------------------------------

.. figure:: /images/data-model-12-in-memory.png
   :width: 700px
   :align: center


..   :title: Documents with Only Useful Data (Solution #2)

.. only:: instructor

   .. note::

     - Now the same size of memory now contains more documents (12)
     - Because all of the data is useful, there is space for more documents.
     - This results in:
     
       - Fewer page faults
       - More effective use of RAM


Scenario #2: Library Card Catalog System
----------------------------------------

- The objective is to keep track of 3 entities.

  - books
  - authors 
  - publishers.
  
- Patrons (not librarians) are the primary users of this system


Library Card Catalog System (Continued)
---------------------------------------

- Users query for books, but often also want:

  - Author information (such as name)
  - Publisher details

- Users also sometimes query for authors
 
  - They may also want publishers the authors have worked with.


Library Card Catalog System (Continued)
---------------------------------------

- Possibility #1: Author References

  - For a book, an array of author _id’s could be embedded.

    - It won't be a simple field because some books have multiple authors.

  - You now have a reference to authors.
  - This would require multiple queries to get your data.

    - One for the book.
    - One for each author.


Library Card Catalog System (Continued)
---------------------------------------

- Possibility #2: "denormalize" the author information into the book.

  - You would copy the author's name and their _id into the book' document.
  - It is important to bring in the _id in case the author name changes.
  - You would *not* want to denormalize the other author information, such as their biography.

    - That would not be useful in the context of the book.

  - Now book info can be gathered with one query.

    - More author information is available if needed.


Library Card Catalog System (Continued)
---------------------------------------

- If you wanted to add “genre”  or “category” information:

  - Don't build a lookup table.
  - Instead, embed as an array of categories or genres.

    - This can be indexed.

  - Books of the same category will be found with one search.


Atomic Operations in MongoDB
----------------------------
- MongoDB has "atomic operations" on documents.

  - Only documents, not collections.

- When a document is updated, no other thread is updating it or reading it.

  - This leads to consistent reads and writes.
  - This feature provides document-level transactions.


Atomic Operations in MongoDB (Continued)
----------------------------------------

- Any modification to any number of fields in a single document can be thought of as a transaction.
- Updates to a single document either entirely happen or they do not at all.
- There are no partial updates and no “dirty reads” at the document level.
- You can use this to your advantage if you have data put together in one document.



.. include:: /exercises/schema-design-atomic-operations.txt
